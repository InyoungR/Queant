우선적으로 데이터 활용할 내용  
* 기사나 게시글 들을 모아서 단어들을 분류하여 wordclouding하기
* 금융 감독원에서 오픈 API를 가져와서 예적금 데이터를 파싱한 후 front에서 출력
* 기사 크롤링

그렇다면 어떻게 어느 단에서 이 동작을 수행시킬 것인가?

결론  
일단 django로 서버를 하나 더 만들어서 데이터 부분을 따로 다룰 예정
회원관리 -> spring
데이터활용 -> django

1. 기사나 게시글 들을 모아서 단어들을 분류하여 wordclouding하기
    * 우선적으로 파이썬 library중에 wordcloud가 있음
    * 하지만 서버에서 이미지를 생성후 front에 보내기는 속도 측면에서 안좋을 것 같다.(직접 적용해서 실험할 예정)
    * konlpy 라이브러리로 단어 추출 후 등장 횟수를 판별하여 중요도에 따라 정렬후 wordcloud에 적용

wordcloud 구현코드(vs코드에서 실행한 결과 정상 동작)
```python
from wordcloud import WordCloud
from konlpy.tag import Okt
from collections import Counter
import matplotlib.pyplot as plt

with open('test.txt', 'r', encoding='utf-8') as f:
    text = f.read()


twitter = Okt()

sentences_tag = []
sentences_tag = twitter.pos(text) 
noun_adj_list = []

# tag가 명사이거나 형용사인 단어들만 noun_adj_list에 넣어준다.
for word, tag in sentences_tag:
    if tag in ['Noun' , 'Adjective']: 
        noun_adj_list.append(word)

# 가장 많이 나온 단어부터 40개를 저장한다.
counts = Counter(noun_adj_list)
tags = counts.most_common(50) 

# WordCloud를 생성한다.
# 한글을 분석하기위해 font를 한글로 지정해주어야 된다. macOS는 .otf , window는 .ttf 파일의 위치를
# 지정해준다. (ex. '/Font/GodoM.otf')
wc = WordCloud(font_path='malgun',background_color="white", max_font_size=60)
cloud = wc.generate_from_frequencies(dict(tags))

# 생성된 WordCloud를 test.jpg로 보낸다.
plt.figure(figsize=(10, 8))
plt.axis('off')
plt.imshow(cloud)
plt.show()
```


2. 금융 감독원에서 오픈 API를 가져와서 예적금 데이터를 파싱한 후 front에서 출력
    * 우선 front와 협의 후 진행할 예정

3. 기사 크롤링
    * front와 협의 후 진행할 예정